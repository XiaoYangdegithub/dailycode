{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595bb02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.3-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce37c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlepaddle\n",
      "  Downloading paddlepaddle-2.4.0-cp310-cp310-macosx_11_0_arm64.whl (46.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m822.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting paddle-bfloat==0.1.7\n",
      "  Downloading paddle_bfloat-0.1.7-cp310-cp310-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from paddlepaddle) (1.21.5)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from paddlepaddle) (2.25.1)\n",
      "Collecting opt-einsum==3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from paddlepaddle) (5.1.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from paddlepaddle) (9.3.0)\n",
      "Collecting protobuf<=3.20.0,>=3.1.0\n",
      "  Downloading protobuf-3.20.0-cp310-cp310-macosx_10_9_universal2.whl (962 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.3/962.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from paddlepaddle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20.0->paddlepaddle) (2022.9.24)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20.0->paddlepaddle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20.0->paddlepaddle) (1.26.13)\n",
      "Installing collected packages: paddle-bfloat, protobuf, opt-einsum, astor, paddlepaddle\n",
      "Successfully installed astor-0.8.1 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddlepaddle-2.4.0 protobuf-3.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c592b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.23.5\n",
      "Uninstalling numpy-1.23.5:\n",
      "  Successfully uninstalled numpy-1.23.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a1bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a11cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a517daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.64.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0974eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/faiss/loader.py:28: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numpy.__version__) >= \"1.19\":\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle import nn\n",
    "from paddle.io import DataLoader, Dataset\n",
    "import paddle.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score,log_loss\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import faiss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f48aca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "class SeqnenceDataset(Dataset):\n",
    "    def __init__(self, config, df, phase='train'):\n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.max_length = self.config['max_length']\n",
    "        self.df = self.df.sort_values(by=['user_id', 'timestamp'])\n",
    "        self.user2item = self.df.groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "        self.user_list = self.df['user_id'].unique()\n",
    "        self.phase = phase\n",
    "    def __len__(self, ):\n",
    "        return len(self.user2item)\n",
    "    def __getitem__(self, index):\n",
    "        if self.phase == 'train':\n",
    "            user_id = self.user_list[index]\n",
    "            item_list = self.user2item[user_id]\n",
    "            hist_item_list = []\n",
    "            hist_mask_list = []\n",
    "            k = random.choice(range(4, len(item_list)))\n",
    "            item_id = item_list[k] \n",
    "            if k >= self.max_length: \n",
    "                hist_item_list.append(item_list[k - self.max_length: k])\n",
    "                hist_mask_list.append([1.0] * self.max_length)\n",
    "            else:\n",
    "                hist_item_list.append(item_list[:k] + [0] * (self.max_length - k))\n",
    "                hist_mask_list.append([1.0] * k + [0.0] * (self.max_length - k))\n",
    "\n",
    "            return paddle.to_tensor(hist_item_list).squeeze(0), paddle.to_tensor(hist_mask_list).squeeze(\n",
    "                0), paddle.to_tensor([item_id])\n",
    "        else:\n",
    "            user_id = self.user_list[index]\n",
    "            item_list = self.user2item[user_id]\n",
    "            hist_item_list = []\n",
    "            hist_mask_list = []\n",
    "            k = int(0.8 * len(item_list))\n",
    "            if k >= self.max_length: \n",
    "                hist_item_list.append(item_list[k - self.max_length: k])\n",
    "                hist_mask_list.append([1.0] * self.max_length)\n",
    "            else:\n",
    "                hist_item_list.append(item_list[:k] + [0] * (self.max_length - k))\n",
    "                hist_mask_list.append([1.0] * k + [0.0] * (self.max_length - k))\n",
    "            return paddle.to_tensor(hist_item_list).squeeze(0), paddle.to_tensor(hist_mask_list).squeeze(\n",
    "                0), item_list[k:]\n",
    "\n",
    "    def get_test_gd(self):\n",
    "        self.test_gd = {}\n",
    "        for user in self.user2item:\n",
    "            item_list = self.user2item[user]\n",
    "            test_item_index = int(0.8 * len(item_list))\n",
    "            self.test_gd[user] = item_list[test_item_index:]\n",
    "        return self.test_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2a66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础序列召回模型\n",
    "class GRU4Rec(nn.Layer):\n",
    "    def __init__(self, config):\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.config = config\n",
    "        self.embedding_dim = self.config['embedding_dim']\n",
    "        self.max_length = self.config['max_length']\n",
    "        self.n_items = self.config['n_items']\n",
    "        self.num_layers = self.config['num_layers']\n",
    "        self.item_emb = nn.Embedding(self.n_items, self.embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.embedding_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            time_major=False,\n",
    "        )\n",
    "        self.loss_fun = nn.CrossEntropyLoss()\n",
    "        self.reset_parameters()\n",
    "    def calculate_loss(self,user_emb,pos_item):\n",
    "        all_items = self.item_emb.weight\n",
    "        scores = paddle.matmul(user_emb, all_items.transpose([1, 0]))\n",
    "        return self.loss_fun(scores,pos_item)\n",
    "    \n",
    "    def output_items(self):\n",
    "        return self.item_emb.weight\n",
    "    \n",
    "    def reset_parameters(self, initializer=None):\n",
    "        for weight in self.parameters():\n",
    "            paddle.nn.initializer.KaimingNormal(weight)\n",
    "            \n",
    "    def forward(self, item_seq, mask, item, train=True):\n",
    "        seq_emb = self.item_emb(item_seq)\n",
    "        seq_emb,_ = self.gru(seq_emb)\n",
    "        user_emb = seq_emb[:,-1,:] \n",
    "        if train:\n",
    "            loss = self.calculate_loss(user_emb,item)\n",
    "            output_dict = {\n",
    "                'user_emb':user_emb,\n",
    "                'loss':loss\n",
    "            }\n",
    "        else:\n",
    "            output_dict = {\n",
    "                'user_emb':user_emb\n",
    "            }\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7deada68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "config = {\n",
    "    'train_path':'/home/aistudio/data/data173799/train_enc.csv',\n",
    "    'valid_path':'/home/aistudio/data/data173799/valid_enc.csv',\n",
    "    'test_path':'/home/aistudio/data/data173799/test_enc.csv',\n",
    "    'lr':1e-4,\n",
    "    'Epoch':100,\n",
    "    'batch_size':256,\n",
    "    'embedding_dim':16,\n",
    "    'num_layers':1,\n",
    "    'max_length':20,\n",
    "    'n_items':15406,\n",
    "    'K':4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72246605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    hist_item, hist_mask, item_list = list(zip(*batch))\n",
    "\n",
    "    hist_item = [x.unsqueeze(0) for x in hist_item]\n",
    "    hist_mask = [x.unsqueeze(0) for x in hist_mask]\n",
    "\n",
    "    hist_item = paddle.concat(hist_item,axis=0)\n",
    "    hist_mask = paddle.concat(hist_mask,axis=0)\n",
    "    return hist_item,hist_mask,item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d660f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    paddle.save(model.state_dict(), path + 'model.pdparams')\n",
    "def load_model(model, path):\n",
    "    state_dict = paddle.load(path + 'model.pdparams')\n",
    "    model.set_state_dict(state_dict)\n",
    "    print('model loaded from %s' % path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于faiss的向量召回\n",
    "def get_predict(model, test_data, hidden_size, topN=20):\n",
    "    item_embs = model.output_items().cpu().detach().numpy()\n",
    "    item_embs = normalize(item_embs, norm='l2')\n",
    "    gpu_index = faiss.IndexFlatIP(hidden_size)\n",
    "    gpu_index.add(item_embs)    \n",
    "    test_gd = dict()\n",
    "    preds = dict() \n",
    "    user_id = 0\n",
    "\n",
    "    for (item_seq, mask, targets) in tqdm(test_data): # 获取用户嵌入\n",
    "        user_embs = model(item_seq,mask,None,train=False)['user_emb']\n",
    "        user_embs = user_embs.cpu().detach().numpy()\n",
    "# 使用内积作为指标，内积越大越相似\n",
    "# 多兴趣模型，shape=(batch_size, num_interest, embedding_dim)\n",
    "# 其他模型，shape=(batch_size, embedding_dim)\n",
    "    if len(user_embs.shape) == 2: # 非多兴趣模型\n",
    "            user_embs = normalize(user_embs, norm='l2').astype('float32')\n",
    "            D, I = gpu_index.search(user_embs, topN)\n",
    "            for i, iid_list in enumerate(targets): \n",
    "                test_gd[user_id] = iid_list\n",
    "                preds[user_id] = I[i,:]\n",
    "                user_id +=1\n",
    "    else:  # 多兴趣模型\n",
    "            ni = user_embs.shape[1] \n",
    "            user_embs = np.reshape(user_embs,\n",
    "                                   [-1, user_embs.shape[-1]])  \n",
    "            user_embs = normalize(user_embs, norm='l2').astype('float32')\n",
    "            D, I = gpu_index.search(user_embs, topN)  \n",
    "            for i, iid_list in enumerate(targets):  \n",
    "                recall = 0\n",
    "                dcg = 0.0\n",
    "                item_list_set = []\n",
    "                item_list = list(\n",
    "                    zip(np.reshape(I[i * ni:(i + 1) * ni], -1), np.reshape(D[i * ni:(i + 1) * ni], -1)))\n",
    "                item_list.sort(key=lambda x: x[1], reverse=True)  \n",
    "                for j in range(len(item_list)): \n",
    "                    if item_list[j][0] not in item_list_set and item_list[j][0] != 0:\n",
    "                        item_list_set.append(item_list[j][0])\n",
    "                        if len(item_list_set) >= topN:\n",
    "                            break\n",
    "                test_gd[user_id] = iid_list\n",
    "                preds[user_id] = item_list_set\n",
    "                user_id +=1\n",
    "    return test_gd, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a21035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds,test_gd, topN=50):\n",
    "    total_recall = 0.0\n",
    "    total_ndcg = 0.0\n",
    "    total_hitrate = 0\n",
    "    for user in test_gd.keys():\n",
    "        recall = 0\n",
    "        dcg = 0.0\n",
    "        item_list = test_gd[user]\n",
    "        for no, item_id in enumerate(item_list):\n",
    "            if item_id in preds[user][:topN]:\n",
    "                recall += 1\n",
    "                dcg += 1.0 / math.log(no+2, 2)\n",
    "            idcg = 0.0\n",
    "            for no in range(recall):\n",
    "                idcg += 1.0 / math.log(no+2, 2)\n",
    "        total_recall += recall * 1.0 / len(item_list)\n",
    "        if recall > 0:\n",
    "            total_ndcg += dcg / idcg\n",
    "            total_hitrate += 1\n",
    "    total = len(test_gd)\n",
    "    recall = total_recall / total\n",
    "    ndcg = total_ndcg / total\n",
    "    hitrate = total_hitrate * 1.0 / total\n",
    "    return {f'recall@{topN}': recall, f'ndcg@{topN}': ndcg, f'hitrate@{topN}': hitrate}\n",
    "def evaluate_model(model, test_loader, embedding_dim,topN=20):\n",
    "    test_gd, preds = get_predict(model, test_loader, embedding_dim, topN=topN)\n",
    "    return evaluate(preds, test_gd, topN=topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cb3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
